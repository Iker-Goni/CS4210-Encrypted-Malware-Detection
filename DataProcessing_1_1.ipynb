{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd559399",
   "metadata": {},
   "source": [
    " # Project: Network Intrusion Detection\n",
    "\n",
    "### Use machine learning to train a model to be able to detect whether incoming network traffic contains encrypted malware or not through pattern recognition.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ca62544",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from scipy.spatial.distance import pdist, squareform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07fb03ff",
   "metadata": {},
   "source": [
    "## DoH Dataset & NonDoH Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4fc890d",
   "metadata": {},
   "source": [
    "### DoH: DNS over HTTP (DoH) vs NonDoH\n",
    "##### DoH encrypts DNS queries within HTTPS connections, making it challenging for network security tools to inspect and filter DNS traffic. The malware authors can utilize DoH to hide their malicious activities within encrypted DNS traffic, making it harder for network administrators to detect and block malicious domains or IP addresses associated with the malware.\n",
    "##### We use DoH from dnscat2 which is the file contains network traffic data generated by the dnscat2 tool. dnscat2 is another DNS tunneling tool similar to dns2tcp, which can be used for malicious purposes such as data exfiltration or command-and-control communication.\n",
    "##### For non DoH dataset, we use the file contains the network traffic data captured when browsing websites using the Google Chrome browser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ade36bf3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'MaliciousDoH_dnscat2.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_21604\\3990508239.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDoH_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'MaliciousDoH_dnscat2.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    676\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 678\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    679\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    680\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 575\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    576\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    577\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    930\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    931\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[1;33m|\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 932\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    933\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    934\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1214\u001b[0m             \u001b[1;31m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1215\u001b[0m             \u001b[1;31m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1216\u001b[1;33m             self.handles = get_handle(  # type: ignore[call-overload]\n\u001b[0m\u001b[0;32m   1217\u001b[0m                 \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1218\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    784\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;34m\"b\"\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    785\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 786\u001b[1;33m             handle = open(\n\u001b[0m\u001b[0;32m    787\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'MaliciousDoH_dnscat2.csv'"
     ]
    }
   ],
   "source": [
    "df = DoH_data = pd.read_csv('MaliciousDoH_dnscat2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d60c75b5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_21604\\3560225417.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "print(df.head()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9825fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    " # Display the first few rows of the DataFrame\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab9ffd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = Non_DoH_data = pd.read_csv(\"None_DoH_Chrome.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9d5918",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df2.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ea66dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df2.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "946405a5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_21604\\431819642.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "print(len(df), len(df2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e39bbe",
   "metadata": {},
   "source": [
    "## Identify missing value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f90bda05",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# DoH dataset\n",
    "\n",
    "# Check for missing values\n",
    "missing_values = df.isnull().sum()\n",
    "\n",
    "# Display columns with missing values\n",
    "print(\"Columns with missing values:\")\n",
    "print(missing_values[missing_values > 0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adab1d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DoH dataset\n",
    "\n",
    "# Check for missing values\n",
    "missing_values = df2.isnull().sum()\n",
    "\n",
    "# Display columns with missing values\n",
    "print(\"Columns with missing values:\")\n",
    "print(missing_values[missing_values > 0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f0e09c",
   "metadata": {},
   "source": [
    "##  mean/median imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e416276",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ResponseTimeTimeMedian'].fillna(df['ResponseTimeTimeMedian'].mean(), inplace=True)\n",
    "df['ResponseTimeTimeSkewFromMedian'].fillna(df['ResponseTimeTimeSkewFromMedian'].mean(), inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b571d4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking again for missing value after the imputation\n",
    "missing_values = df.isnull().sum()\n",
    "\n",
    "\n",
    "print(\"Columns with missing values:\")\n",
    "print(missing_values[missing_values > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05ac119",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DoH \n",
    "\n",
    "# Impute missing values with median\n",
    "median_median = df2['ResponseTimeTimeMedian'].median()\n",
    "median_skew = df2['ResponseTimeTimeSkewFromMedian'].median()\n",
    "\n",
    "df2['ResponseTimeTimeMedian'].fillna(median_median, inplace=True)\n",
    "df2['ResponseTimeTimeSkewFromMedian'].fillna(median_skew, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85694cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking again for missing value after the imputation\n",
    "missing_values = df2.isnull().sum()\n",
    "\n",
    "\n",
    "print(\"Columns with missing values:\")\n",
    "print(missing_values[missing_values > 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b4e5573",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e524f581",
   "metadata": {},
   "source": [
    "## Packet Length statistics \n",
    "\n",
    "##### A packet is a unit of data transmitted over a network. It consists of two main parts: a header and a payload.  The packet length represents the number of bytes or bits contained within the packet. The payload contains the actual data being transmitted, such as a segment of a file, an email message, or a request to a web server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7966ea6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Packet length statistics for DoH traffic\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(df['PacketLengthVariance'], bins=50, range=(0, 1000), color='blue', alpha=0.7)\n",
    "plt.title('Packet Length Variance Frequency for DoH Traffic')\n",
    "plt.xlabel('Packet Length Variance')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(df2['PacketLengthVariance'], bins=50, range=(0, 1000), color='red', alpha=0.7)\n",
    "plt.title('Packet Length Variance Frequency for non-DoH Traffic')\n",
    "plt.xlabel('Packet Length Variance')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ba42a3",
   "metadata": {},
   "source": [
    "## Packet Time statistics \n",
    "\n",
    "#####  Packet time statistics refer to the analysis of timing characteristics associated with network packets. These statistics provide insights into the timing aspects of packet transmission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a5de50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packet time statistics for DoH traffic\n",
    "\n",
    "# Create a figure and subplots with 1 row and 2 columns\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Packet time statistics for DoH traffic\n",
    "sns.histplot(x='PacketTimeMean', data=df, color='blue', kde=True, ax=ax1)\n",
    "ax1.set_title('Packet Time Mean Distribution for DoH Traffic')\n",
    "ax1.set_xlabel('Packet Time Mean')\n",
    "ax1.set_ylabel('Frequency')\n",
    "\n",
    "# Packet time statistics for non-DoH traffic\n",
    "sns.histplot(x='PacketTimeMean', data=df2, color='blue', kde=True, ax=ax2)\n",
    "ax2.set_title('Packet Time Mean Distribution for non-DoH Traffic')\n",
    "ax2.set_xlabel('Packet Time Mean')\n",
    "ax2.set_ylabel('Frequency')\n",
    "ax2.set_yscale('log')  # Set y-axis scale to logarithmic\n",
    "\n",
    "# Adjust the spacing between subplots\n",
    "plt.tight_layout()\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9275838",
   "metadata": {},
   "source": [
    "## Response Time Statistics\n",
    "\n",
    "#####  a response refers to the data sent back by a server or destination in response to a request initiated by a client or source.Response time, also known as latency, measures the time taken for a system to respond to a request after it has been sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c5caaa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = pd.concat([df, df2], keys=['DoH Traffic', 'Non-DoH Traffic'])\n",
    "combined_df = combined_df.reset_index(level=0).rename(columns={'level_0': 'Traffic Type'})\n",
    "\n",
    "# Create a box plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.boxplot(x='Traffic Type', y='ResponseTimeTimeMedian', data=combined_df)\n",
    "plt.title('Comparison of ResponseTimeTimeMedian')\n",
    "plt.xlabel('Traffic Type')\n",
    "plt.ylabel('ResponseTimeTimeMedian')\n",
    "plt.show()\n",
    "\n",
    "# Create a violin plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.violinplot(x='Traffic Type', y='ResponseTimeTimeMedian', data=combined_df)\n",
    "plt.title('Comparison of ResponseTimeTimeMedian')\n",
    "plt.xlabel('Traffic Type')\n",
    "plt.ylabel('ResponseTimeTimeMedian')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ddc8c0",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfdcfeed",
   "metadata": {},
   "source": [
    "# Removing Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e7f59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_for_outliers = ['Duration', 'FlowBytesSent', 'FlowSentRate', 'FlowBytesReceived', 'FlowReceivedRate', 'PacketTimeCoefficientofVariation', 'PacketLengthStandardDeviation', 'PacketLengthMean', 'PacketLengthMedian', 'PacketLengthMode',\n",
    "            'PacketLengthSkewFromMedian', 'PacketLengthSkewFromMode', 'PacketLengthCoefficientofVariation',\n",
    "            'PacketTimeVariance', 'PacketTimeStandardDeviation', 'PacketTimeMean', 'PacketTimeMedian',\n",
    "            'PacketTimeMode', 'PacketTimeSkewFromMedian', 'PacketTimeSkewFromMode', 'PacketTimeCoefficientofVariation',\n",
    "             'ResponseTimeTimeStandardDeviation', 'ResponseTimeTimeMean',\n",
    "            'ResponseTimeTimeMedian', 'ResponseTimeTimeMode', 'ResponseTimeTimeSkewFromMedian',\n",
    "            'ResponseTimeTimeSkewFromMode', 'ResponseTimeTimeCoefficientofVariation']\n",
    "z_scores = stats.zscore(df[columns_for_outliers])\n",
    "\n",
    "threshold = 4\n",
    "\n",
    "df_no_outliers = df[(abs(z_scores) < threshold).all(axis=1)]\n",
    "df = df_no_outliers\n",
    "\n",
    "print(\"Original DataFrame:\")\n",
    "print(df)\n",
    "print(\"\\nDataFrame without outliers in certain columns\")\n",
    "print(df_no_outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d014061",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_for_outliers = ['Duration', 'FlowBytesSent', 'FlowSentRate', 'FlowBytesReceived', 'FlowReceivedRate', 'PacketTimeCoefficientofVariation', 'PacketLengthStandardDeviation', 'PacketLengthMean', 'PacketLengthMedian', 'PacketLengthMode',\n",
    "            'PacketLengthSkewFromMedian', 'PacketLengthSkewFromMode', 'PacketLengthCoefficientofVariation',\n",
    "            'PacketTimeVariance', 'PacketTimeStandardDeviation', 'PacketTimeMean', 'PacketTimeMedian',\n",
    "            'PacketTimeMode', 'PacketTimeSkewFromMedian', 'PacketTimeSkewFromMode', 'PacketTimeCoefficientofVariation',\n",
    "             'ResponseTimeTimeStandardDeviation', 'ResponseTimeTimeMean',\n",
    "            'ResponseTimeTimeMedian', 'ResponseTimeTimeMode', 'ResponseTimeTimeSkewFromMedian',\n",
    "            'ResponseTimeTimeSkewFromMode', 'ResponseTimeTimeCoefficientofVariation']\n",
    "\n",
    "z_scores = stats.zscore(df2[columns_for_outliers])\n",
    "\n",
    "threshold = 4\n",
    "\n",
    "df2_no_outliers = df2[(abs(z_scores) < threshold).all(axis=1)]\n",
    "df2 = df2_no_outliers\n",
    "\n",
    "print(\"Original DataFrame:\")\n",
    "print(df2)\n",
    "print(\"\\nDataFrame without outliers in certain columns\")\n",
    "print(df2_no_outliers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "298dd480",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Packet time statistics for DoH traffic\n",
    "\n",
    "# Create a figure and subplots with 1 row and 2 columns\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Packet time statistics for DoH traffic\n",
    "sns.histplot(x='PacketTimeMean', data=df, color='blue', kde=True, ax=ax1)\n",
    "ax1.set_title('Packet Time Mean Distribution for DoH Traffic')\n",
    "ax1.set_xlabel('Packet Time Mean')\n",
    "ax1.set_ylabel('Frequency')\n",
    "\n",
    "# Packet time statistics for non-DoH traffic\n",
    "sns.histplot(x='PacketTimeMean', data=df2, color='blue', kde=True, ax=ax2)\n",
    "ax2.set_title('Packet Time Mean Distribution for non-DoH Traffic')\n",
    "ax2.set_xlabel('Packet Time Mean')\n",
    "ax2.set_ylabel('Frequency')\n",
    "ax2.set_yscale('log')  # Set y-axis scale to logarithmic\n",
    "\n",
    "# Adjust the spacing between subplots\n",
    "plt.tight_layout()\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b075f47d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# removing identical instances\n",
    "df_no_outliers.drop_duplicates()\n",
    "df_no_outliers.reset_index(drop = True, inplace = True)\n",
    "print(df_no_outliers)\n",
    "\n",
    "df2_no_outliers.drop_duplicates()\n",
    "df2_no_outliers.reset_index(drop = True, inplace = True)\n",
    "print(df2_no_outliers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37bccb2a",
   "metadata": {},
   "source": [
    "## Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888f73fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['SourcePort', 'DestinationPort', 'Duration', 'FlowBytesSent', 'FlowSentRate', \n",
    "            'FlowBytesReceived', 'FlowReceivedRate', 'PacketLengthVariance', 'PacketLengthStandardDeviation', 'PacketLengthMean', \n",
    "            'PacketLengthMedian', 'PacketLengthMode', 'PacketLengthSkewFromMedian', 'PacketLengthSkewFromMode', 'PacketLengthCoefficientofVariation',\n",
    "            'PacketTimeVariance', 'PacketTimeStandardDeviation', 'PacketTimeMean', 'PacketTimeMedian', 'PacketTimeMode', 'PacketTimeSkewFromMedian', \n",
    "            'PacketTimeSkewFromMode', 'PacketTimeCoefficientofVariation', 'ResponseTimeTimeVariance', 'ResponseTimeTimeStandardDeviation', 'ResponseTimeTimeMean', 'ResponseTimeTimeMedian',\n",
    "            'ResponseTimeTimeMode', 'ResponseTimeTimeSkewFromMedian', 'ResponseTimeTimeSkewFromMode', 'ResponseTimeTimeCoefficientofVariation']\n",
    "\n",
    "# Calculate the correlation matrix using the specified features\n",
    "corr_matrix = df[features].corr()\n",
    "\n",
    "# Print the correlation matrix\n",
    "print(corr_matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf24b91f",
   "metadata": {},
   "source": [
    "#### Positive correlatioons: dark red such as Packettimestandared deviation and packet time mean\n",
    "#### Negative correlation: dark blue such as 'ResponseTimeTimeCoefficicentVariation' and several other features like 'PacketLengthMean', 'PacketLengthMedian', and 'PacketLengthMode'\n",
    "#### Low or no correlation: The yellow PacketLengthVariance' seems to have low or no correlation with many other features,\n",
    "#### features related to packet length (e.g., 'PacketLengthMean', 'PacketLengthMedian', 'PacketLengthMode') are highly correlated among themselves, but less correlated with features related to response time or packet time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ac7a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18, 18))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f803c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "highly_correlated = (corr_matrix > 0.9) & (corr_matrix < 1.0)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(highly_correlated, cmap='coolwarm', annot=True, fmt=\".0%\", cbar=False)\n",
    "plt.title('Highly Correlated Features')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c7db95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify highly correlated features\n",
    "highly_correlated = (corr_matrix > 0.9) & (corr_matrix < 1.0)\n",
    "\n",
    "# Create a set to store the features to drop\n",
    "features_to_drop = set()\n",
    "\n",
    "# Iterate over the pairs of highly correlated features\n",
    "for i in range(len(highly_correlated)):\n",
    "    for j in range(i+1, len(highly_correlated)):\n",
    "        if highly_correlated.iloc[i, j]:\n",
    "            feature_i = highly_correlated.columns[i]\n",
    "            feature_j = highly_correlated.columns[j]\n",
    "            features_to_drop.add(feature_i)\n",
    "\n",
    "# Drop the highly correlated features from the DataFrame\n",
    "reduced_df = df.drop(columns=list(features_to_drop))\n",
    "\n",
    "print(reduced_df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c16d62b",
   "metadata": {},
   "source": [
    "## NonDoH "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548b6f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NonDoH\n",
    "\n",
    "corr_matrix = df2[features].corr()\n",
    "\n",
    "# Print the correlation matrix\n",
    "print(corr_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a1e418",
   "metadata": {},
   "source": [
    "#### Positive correlatioons:  'PacketTimeStandardDeviation' and 'PacketTimeMean', 'PacketTimeMedian' and 'PacketTimeMean', and among various packet length-related features like 'PacketLengthMean', 'PacketLengthMedian', and 'PacketLengthMode'.\n",
    "#### Negative correlation: ResponseTimeTimeCoefficicentVariation' has a strong negative correlation with features like 'PacketLengthMean', 'PacketLengthMedian', and 'PacketLengthMode'.\n",
    "#### Low correlated:  'PacketLengthVariance', which appears to have low or no correlation with many other feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05282f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18, 18))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61cff98",
   "metadata": {},
   "outputs": [],
   "source": [
    "highly_correlated = (corr_matrix > 0.9) & (corr_matrix < 1.0)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(highly_correlated, cmap='coolwarm', annot=True, fmt=\".0%\", cbar=False)\n",
    "plt.title('Highly Correlated Features')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e32234",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Identify highly correlated features\n",
    "highly_correlated = (corr_matrix > 0.9) & (corr_matrix < 1.0)\n",
    "\n",
    "# Drop highly correlated features\n",
    "reduced_df2 = df2.drop(columns=corr_matrix.columns[highly_correlated.sum() > 1])\n",
    "\n",
    "print(reduced_df2.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd91f3c7",
   "metadata": {},
   "source": [
    "# Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af88e8b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "columns_to_normalize = ['Duration', 'FlowBytesSent', 'FlowSentRate', 'FlowBytesReceived', 'FlowReceivedRate', 'PacketTimeCoefficientofVariation', 'PacketLengthStandardDeviation', 'PacketLengthMean', 'PacketLengthMedian', 'PacketLengthMode',\n",
    "            'PacketLengthSkewFromMedian', 'PacketLengthSkewFromMode', 'PacketLengthCoefficientofVariation',\n",
    "            'PacketTimeVariance', 'PacketTimeStandardDeviation', 'PacketTimeMean', 'PacketTimeMedian',\n",
    "            'PacketTimeMode', 'PacketTimeSkewFromMedian', 'PacketTimeSkewFromMode', 'PacketTimeCoefficientofVariation',\n",
    "             'ResponseTimeTimeStandardDeviation', 'ResponseTimeTimeMean',\n",
    "            'ResponseTimeTimeMedian', 'ResponseTimeTimeMode', 'ResponseTimeTimeSkewFromMedian',\n",
    "            'ResponseTimeTimeSkewFromMode', 'ResponseTimeTimeCoefficientofVariation']\n",
    "\n",
    "min_max_scaler = MinMaxScaler()\n",
    "df[columns_to_normalize] = min_max_scaler.fit_transform(df[columns_to_normalize])\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10740c66",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "columns_to_normalize = ['Duration', 'FlowBytesSent', 'FlowSentRate', 'FlowBytesReceived', 'FlowReceivedRate', 'PacketTimeCoefficientofVariation', 'PacketLengthStandardDeviation', 'PacketLengthMean', 'PacketLengthMedian', 'PacketLengthMode',\n",
    "            'PacketLengthSkewFromMedian', 'PacketLengthSkewFromMode', 'PacketLengthCoefficientofVariation',\n",
    "            'PacketTimeVariance', 'PacketTimeStandardDeviation', 'PacketTimeMean', 'PacketTimeMedian',\n",
    "            'PacketTimeMode', 'PacketTimeSkewFromMedian', 'PacketTimeSkewFromMode', 'PacketTimeCoefficientofVariation',\n",
    "             'ResponseTimeTimeStandardDeviation', 'ResponseTimeTimeMean',\n",
    "            'ResponseTimeTimeMedian', 'ResponseTimeTimeMode', 'ResponseTimeTimeSkewFromMedian',\n",
    "            'ResponseTimeTimeSkewFromMode', 'ResponseTimeTimeCoefficientofVariation']\n",
    "\n",
    "min_max_scaler = MinMaxScaler()\n",
    "df2[columns_to_normalize] = min_max_scaler.fit_transform(df2[columns_to_normalize])\n",
    "\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a21d07",
   "metadata": {},
   "source": [
    "# Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c8494c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded = pd.get_dummies(df_no_outliers, columns=['SourceIP', 'DestinationIP'])\n",
    "\n",
    "print(df_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20c0324",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df['DoH'] = df['DoH'].astype(int)\n",
    "\n",
    "def ip_to_binary(ip):\n",
    "    octets = ip.split('.')\n",
    "    binary_octets = [format(int(octet), '08b') for octet in octets]\n",
    "    binary_string = ''.join(binary_octets)\n",
    "    return binary_string\n",
    "\n",
    "# Apply the function to convert IP addresses to binary\n",
    "df['SourceBinaryIP'] = df['SourceIP'].apply(ip_to_binary)\n",
    "df['DestinationBinaryIP'] = df['DestinationIP'].apply(ip_to_binary)\n",
    "\n",
    "# Function to convert binary string to decimal\n",
    "def binary_to_decimal(binary_string):\n",
    "    return int(binary_string, 2)\n",
    "\n",
    "# Convert binary IP to decimal\n",
    "df['SourceDecimalIP'] = df['SourceBinaryIP'].apply(binary_to_decimal)\n",
    "df['DestinationDecimalIP'] = df['DestinationBinaryIP'].apply(binary_to_decimal)\n",
    "\n",
    "df.drop(columns=['SourceIP', 'SourceBinaryIP', 'DestinationIP', 'DestinationBinaryIP'], inplace=True)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8143efb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['DoH'] = df2['DoH'].astype(int)\n",
    "\n",
    "def ip_to_binary(ip):\n",
    "    octets = ip.split('.')\n",
    "    binary_octets = [format(int(octet), '08b') for octet in octets]\n",
    "    binary_string = ''.join(binary_octets)\n",
    "    return binary_string\n",
    "\n",
    "# Apply the function to convert IP addresses to binary\n",
    "df2['SourceBinaryIP'] = df2['SourceIP'].apply(ip_to_binary)\n",
    "df2['DestinationBinaryIP'] = df2['DestinationIP'].apply(ip_to_binary)\n",
    "\n",
    "# Function to convert binary string to decimal\n",
    "def binary_to_decimal(binary_string):\n",
    "    return int(binary_string, 2)\n",
    "\n",
    "# Convert binary IP to decimal\n",
    "df2['SourceDecimalIP'] = df2['SourceBinaryIP'].apply(binary_to_decimal)\n",
    "df2['DestinationDecimalIP'] = df2['DestinationBinaryIP'].apply(binary_to_decimal)\n",
    "\n",
    "df2.drop(columns=['SourceIP', 'SourceBinaryIP', 'DestinationIP', 'DestinationBinaryIP'], inplace=True)\n",
    "\n",
    "print(df2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b09d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming df and df2 are your DataFrames for dohcsv and non_dohcsv datasets respectively\n",
    "# Determine the number of samples in each dataset\n",
    "num_doh_samples = len(df)\n",
    "num_non_doh_samples = len(df2)\n",
    "\n",
    "# Randomly sample the non_dohcsv dataset to match the length of the dohcsv dataset\n",
    "random_indices = np.random.choice(num_non_doh_samples, size=num_doh_samples, replace=False)\n",
    "non_doh_sampled_df = df2.iloc[random_indices]\n",
    "\n",
    "# Combine the sampled non_dohcsv dataset with the dohcsv dataset\n",
    "combined_df = pd.concat([non_doh_sampled_df, df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8c623d",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(combined_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1106a2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(combined_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da9b499b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
